{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CODE\" data-toc-modified-id=\"CODE-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CODE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Gradient Descent</a></span></li><li><span><a href=\"#Polyak-GD\" data-toc-modified-id=\"Polyak-GD-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Polyak GD</a></span></li><li><span><a href=\"#Nesterov-GD\" data-toc-modified-id=\"Nesterov-GD-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Nesterov GD</a></span></li><li><span><a href=\"#AdaGrad-GD\" data-toc-modified-id=\"AdaGrad-GD-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>AdaGrad GD</a></span></li><li><span><a href=\"#Newton-Method\" data-toc-modified-id=\"Newton-Method-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Newton Method</a></span></li><li><span><a href=\"#BFGS\" data-toc-modified-id=\"BFGS-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>BFGS</a></span></li><li><span><a href=\"#Distance\" data-toc-modified-id=\"Distance-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Distance</a></span></li></ul></li><li><span><a href=\"#TASKS:\" data-toc-modified-id=\"TASKS:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TASKS:</a></span><ul class=\"toc-item\"><li><span><a href=\"#2nd-Task\" data-toc-modified-id=\"2nd-Task-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>2nd Task</a></span><ul class=\"toc-item\"><li><span><a href=\"#Function-Analysis\" data-toc-modified-id=\"Function-Analysis-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Function Analysis</a></span></li><li><span><a href=\"#Calculation-of-optimal-Polyak-parameters\" data-toc-modified-id=\"Calculation-of-optimal-Polyak-parameters-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Calculation of optimal Polyak parameters</a></span></li><li><span><a href=\"#Discussion-and-plot\" data-toc-modified-id=\"Discussion-and-plot-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Discussion and plot</a></span></li></ul></li><li><span><a href=\"#5th-Task---Functions\" data-toc-modified-id=\"5th-Task---Functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>5th Task - Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fun-A\" data-toc-modified-id=\"Fun-A-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Fun A</a></span></li><li><span><a href=\"#Fun-B\" data-toc-modified-id=\"Fun-B-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Fun B</a></span></li><li><span><a href=\"#Fun-C\" data-toc-modified-id=\"Fun-C-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Fun C</a></span></li><li><span><a href=\"#Step-Comparison\" data-toc-modified-id=\"Step-Comparison-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Step Comparison</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fun-A-Analysis\" data-toc-modified-id=\"Fun-A-Analysis-2.2.4.1\"><span class=\"toc-item-num\">2.2.4.1&nbsp;&nbsp;</span>Fun A Analysis</a></span></li><li><span><a href=\"#Fun-B-Analysis\" data-toc-modified-id=\"Fun-B-Analysis-2.2.4.2\"><span class=\"toc-item-num\">2.2.4.2&nbsp;&nbsp;</span>Fun B Analysis</a></span></li></ul></li></ul></li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Linear Regression</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:42.451121Z",
     "start_time": "2021-09-04T13:26:42.042652Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.optimize import line_search\n",
    "import time\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "STEPS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:42.459796Z",
     "start_time": "2021-09-04T13:26:42.453492Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(point,\n",
    "                     lr,\n",
    "                     gradient,\n",
    "                     steps=1,\n",
    "                     prj=lambda x, y: np.array([x, y]),\n",
    "                     isTimed=False,\n",
    "                     runFor=1):\n",
    "    # starting point - point\n",
    "    # lr - learning rate\n",
    "    # gradient -  gradient function\n",
    "    # steps -  how many times to perform the algorithm\n",
    "    # prj - projection for PGD\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        new_point = point - lr * gradient(point)\n",
    "        results.append(prj(*new_point))\n",
    "        point = new_point\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:',elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polyak GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:42.591992Z",
     "start_time": "2021-09-04T13:26:42.586664Z"
    }
   },
   "outputs": [],
   "source": [
    "def polyak(point,\n",
    "           lr,\n",
    "           beta,\n",
    "           gradient,\n",
    "           steps=1,\n",
    "           prj=lambda x, y: np.array([x, y]),\n",
    "           isTimed=False,\n",
    "           runFor=1):\n",
    "    previous = point\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        new_point = point - lr * gradient(point) + beta * (point - previous)\n",
    "        results.append(prj(*new_point))\n",
    "        previous = point\n",
    "        point = new_point\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:',elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:42.758777Z",
     "start_time": "2021-09-04T13:26:42.753479Z"
    }
   },
   "outputs": [],
   "source": [
    "def nesterov(point,\n",
    "             lr,\n",
    "             beta,\n",
    "             gradient,\n",
    "             steps=1,\n",
    "             prj=lambda x, y: np.array([x, y]),\n",
    "             isTimed=False,\n",
    "             runFor=1):\n",
    "    previous = point\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        new_point = point - lr * gradient(\n",
    "            (point + beta * (point - previous))) + beta * (point - previous)\n",
    "        results.append(prj(*new_point))\n",
    "        previous = point\n",
    "        point = new_point\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:',elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:42.922045Z",
     "start_time": "2021-09-04T13:26:42.917205Z"
    }
   },
   "outputs": [],
   "source": [
    "def adagrad(point,\n",
    "            lr,\n",
    "            gradient,\n",
    "            steps=1,\n",
    "            prj=lambda arr: np.array(arr),\n",
    "            isTimed=False,\n",
    "            runFor=1):\n",
    "    eps = 1e-8\n",
    "    d = 0\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        grad = gradient(point)\n",
    "        d = d + grad**2\n",
    "        new_point = point - (lr / np.sqrt(d + eps)) * grad\n",
    "        results.append(prj(new_point))\n",
    "        point = new_point\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:',elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:43.088522Z",
     "start_time": "2021-09-04T13:26:43.084133Z"
    }
   },
   "outputs": [],
   "source": [
    "def newton(point, gradient1, gradient2, steps=1, isTimed=False, runFor=1):\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        new_point = point - gradient1(point) / gradient2(point)\n",
    "        point = new_point\n",
    "        results.append(new_point)\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:', elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:43.282188Z",
     "start_time": "2021-09-04T13:26:43.273810Z"
    }
   },
   "outputs": [],
   "source": [
    "def bfgs(point, func, gradient, steps=1, isTimed=False, runFor=1):\n",
    "    results = []\n",
    "    I = np.eye(point.size, dtype=int)\n",
    "    H = I\n",
    "    eps = 1e-8\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        if isTimed:\n",
    "            step = -1\n",
    "            elapsed = time.time() - start_time\n",
    "        grad = gradient(point)\n",
    "        pk = -np.dot(H, grad)\n",
    "        alpha = line_search(func, gradient, point, pk,maxiter=1000)[0]\n",
    "        if(not alpha):\n",
    "            print('Line Search of BFGS Failed at point:',point)\n",
    "            return results\n",
    "        new_point = point + alpha * pk\n",
    "        results.append(new_point)\n",
    "        if (np.linalg.norm(gradient(new_point)) < eps):\n",
    "            return np.array(results)\n",
    "        sk = new_point - point\n",
    "        point = new_point\n",
    "        new_grad = gradient(new_point)\n",
    "        yk = new_grad - grad\n",
    "        ro = 1.0 / (np.dot(yk, sk))\n",
    "        A1 = I - ro * sk[:, np.newaxis] * yk[np.newaxis, :]\n",
    "        A2 = I - ro * yk[:, np.newaxis] * sk[np.newaxis, :]\n",
    "        H = np.dot(A1, np.dot(\n",
    "            H, A2)) + (ro * sk[:, np.newaxis] * sk[np.newaxis, :])\n",
    "        if (isTimed and elapsed >= runFor):\n",
    "            print('ELAPSED:',elapsed)\n",
    "            return np.array(results)\n",
    "        step += 1\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASKS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Analysis\n",
    "\n",
    "$$f(x, y, z) = x^2 + 2y^2 − 2yz + 4z^2 + 3x − 4y + 5z$$\n",
    "$$\\nabla f(x,y,z) = \\begin{bmatrix}\n",
    "          2x + 3 \\\\\n",
    "           4y - 2z-4 \\\\\n",
    "           -2y+8z+5\n",
    "         \\end{bmatrix}\n",
    " $$\n",
    " $$\\nabla^2 f(x,y,z) = \\begin{bmatrix}\n",
    "          2 \\\\\n",
    "           4 \\\\\n",
    "           8\n",
    "         \\end{bmatrix}\n",
    " $$\n",
    " \n",
    " $$min(f(x,y,z)) = f(-\\frac{3}{2},\\frac{11}{14},-\\frac{3}{7}) = f(-1.5,0.7857,-0.4285) = -\\frac{137}{28} \\approx -4.8928$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:43.990954Z",
     "start_time": "2021-09-04T13:26:43.987308Z"
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[0]**2 + 2 * x[1]**2 - 2 * x[1] * x[2] + 4 * x[2]**2 + 3 * x[\n",
    "        0] - 4 * x[1] + 5 * x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:43.996495Z",
     "start_time": "2021-09-04T13:26:43.993039Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_2(x):\n",
    "    return np.array(\n",
    "        [2 * x[0] + 3, 4 * x[1] - 2 * x[2] - 4, -2 * x[1] + 8 * x[2] + 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:44.001622Z",
     "start_time": "2021-09-04T13:26:43.998504Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad2_2(x):\n",
    "    return np.array([2, 4, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of optimal Polyak parameters\n",
    "$$eigenvalues\\rightarrow \\alpha = 2 \\: \\beta = 8.8284$$\n",
    "\n",
    "$$\\sqrt{\\mu} = \\frac{\\sqrt{\\beta}- \\sqrt{\\alpha}}{\\sqrt{\\beta} + \\sqrt{\\alpha}} \\rightarrow \\mu= 0.126$$\n",
    "\n",
    "$$\\gamma = \\frac{4}{(\\sqrt{\\beta} + \\sqrt{\\alpha})^2} = 0.2081$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:44.364947Z",
     "start_time": "2021-09-04T13:26:44.361852Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:44.369790Z",
     "start_time": "2021-09-04T13:26:44.366865Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient(x, y):\n",
    "    return np.array([2 * x, 10 * y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th Task - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:44.714805Z",
     "start_time": "2021-09-04T13:26:44.709375Z"
    }
   },
   "outputs": [],
   "source": [
    "# for (0,0,0)\n",
    "# min (-1/6,-11/48,1/6)\n",
    "def fun_a(x):\n",
    "    return ((x[0] - x[2])**2 + (2 * x[1] + x[2])**2 +\n",
    "            (4 * x[0] - 2 * x[1] + x[2])**2 + x[0] + x[1])\n",
    "\n",
    "\n",
    "def aprim(x):\n",
    "    return np.array([(34 * x[0] - 16 * x[1] + 6 * x[2] + 1),\n",
    "                     (-16 * x[0] + 16 * x[1] + 1), 6 * (x[0] + x[2])])\n",
    "\n",
    "\n",
    "def aprimprim(x):\n",
    "    return np.array([34, 16, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:44.891868Z",
     "start_time": "2021-09-04T13:26:44.886186Z"
    }
   },
   "outputs": [],
   "source": [
    "# for (1.2,1.2,1.2) and (−1, 1.2, 1.2)\n",
    "# min(1,1,1)\n",
    "def fun_b(x):\n",
    "    return ((x[0] - 1)**2 + (x[1] - 1)**2 + 100 * (x[1] - x[0]**2)**2 + 100 *\n",
    "            (x[2] - x[1]**2)**2)\n",
    "\n",
    "\n",
    "def bprim(x):\n",
    "    return np.array([\n",
    "        (400 * x[0]**3 - 400 * x[0] * x[1] + 2 * x[0] - 2),\n",
    "        (-200 * x[0]**2 + 400 * x[1]**3 + x[1] * (202 - 400 * x[2]) - 2),\n",
    "        200 * (x[2] - x[1]**2)\n",
    "    ])\n",
    "\n",
    "\n",
    "def bprimprim(x):\n",
    "    return np.array([\n",
    "        1200 * x[0]**2 - 400 * x[1] + 2, 1200 * x[1]**2 + 202 - 400 * x[2], 200\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:45.072762Z",
     "start_time": "2021-09-04T13:26:45.061429Z"
    }
   },
   "outputs": [],
   "source": [
    "# for (1,1) and (4.5,4.5)\n",
    "# min(3,0.5)\n",
    "def fun_c(x):\n",
    "    return ((1.5 - x[0] + x[0] * x[1])**2 + (2.25 - x[0] + x[0] * x[1]**2)**2 +\n",
    "            (2.625 - x[0] + x[0] * x[1]**3)**2)\n",
    "\n",
    "\n",
    "def cprim(x):\n",
    "    return np.array([\n",
    "        (2 * x[0] * (x[1]**6 + x[1]**4 - x[1]**2 - 2 * x[1] + 3) +\n",
    "         5.25 * x[1]**3 + 4.5 * x[1]**2 + 3 * x[1] - 12.75),\n",
    "        (6 * x[0] *\n",
    "         (x[0] *\n",
    "          (x[1]**5 + 0.666667 * x[1]**3 - x[1]**2 - 0.333333 * x[1] - 0.333333) +\n",
    "          2.625 * x[1]**2 + 1.5 * x[1] + 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "def cprimprim(x):\n",
    "    return np.array([\n",
    "        2 * (x[1]**6 + x[1]**4 - 2 * x[1]**2 - 2 * x[1] + 3),\n",
    "        (30 * (x[1]**4) * x[0]**2 + 12 * (x[0]**2) * (x[1]**2) - 12 *\n",
    "         (x[0]**2) * x[1] - 1.99 * x[0]**2 + 31.5 * x[1] * x[0] + 9 * x[0])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:45.244703Z",
     "start_time": "2021-09-04T13:26:45.234745Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_analysis(func,\n",
    "               fprim,\n",
    "               fprimprim,\n",
    "               point,\n",
    "               _min,\n",
    "               st=STEPS,\n",
    "               prj=lambda x, y, z: np.array([x, y, z])):\n",
    "    points = gradient_descent(point, 0.001, fprim, st, prj=prj)\n",
    "    print(\"gradient_descent:\",abs(func(_min) - func(points[-1])))\n",
    "    points = polyak(point, 0.001, 0.0009, fprim, st, prj=prj)\n",
    "    print(\"Polyak:\",abs(func(_min) - func(points[-1])))\n",
    "    points = nesterov(point, 0.001, 0.0009, fprim, st, prj=prj)\n",
    "    print(\"Nesterov:\",abs(func(_min) - func(points[-1])))\n",
    "    points = adagrad(point, 1.5, fprim, st)\n",
    "    print(\"Adagrad:\",abs(func(_min) - func(points[-1])))\n",
    "    points = newton(point, fprim, fprimprim, st)\n",
    "    print(\"Newton:\",abs(func(_min) - func(points[-1])))\n",
    "    points = bfgs(point, func, fprim, st)\n",
    "    print(\"BFGS:\",abs(func(_min) - func(points[-1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:45.258882Z",
     "start_time": "2021-09-04T13:26:45.247216Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_analysis_time(func,\n",
    "                    fprim,\n",
    "                    fprimprim,\n",
    "                    point,\n",
    "                    _min,\n",
    "                    _time,\n",
    "                    prj=lambda x, y, z: np.array([x, y, z])):\n",
    "    st = STEPS\n",
    "    points = gradient_descent(point,\n",
    "                              0.001,\n",
    "                              fprim,\n",
    "                              st,\n",
    "                              prj=prj,\n",
    "                              isTimed=True,\n",
    "                              runFor=_time)\n",
    "    print(f'Gradient_descent({len(points)} steps)',abs(func(_min) - func(points[-1]) ))\n",
    "    points = polyak(point,\n",
    "                    0.001,\n",
    "                    0.0009,\n",
    "                    fprim,\n",
    "                    st,\n",
    "                    prj=prj,\n",
    "                    isTimed=True,\n",
    "                    runFor=_time)\n",
    "    print(f'Polyak({len(points)} steps)',abs(func(_min) - func(points[-1]) ))\n",
    "    points = nesterov(point,\n",
    "                      0.001,\n",
    "                      0.0009,\n",
    "                      fprim,\n",
    "                      st,\n",
    "                      prj=prj,\n",
    "                      isTimed=True,\n",
    "                      runFor=_time)\n",
    "    print(f'Nesterov({len(points)} steps)',abs(func(_min) - func(points[-1]) ))\n",
    "    points = adagrad(point, 1.5, fprim, st, isTimed=True, runFor=_time)\n",
    "    print(f'Adagrad({len(points)} steps)',abs(func(_min) - func(points[-1])) )\n",
    "    points = newton(point, fprim, fprimprim, st, isTimed=True, runFor=_time)\n",
    "    print(f'Newton({len(points)} steps)',abs(func(_min) - func(points[-1]) ))\n",
    "    points = bfgs(point, func, fprim, st, isTimed=True, runFor=_time)\n",
    "    print(f'BFGS({len(points)} steps)',abs(func(_min) - func(points[-1]) ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun A Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For point (0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:26:45.717653Z",
     "start_time": "2021-09-04T13:26:45.595835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 steps:\n",
      "gradient_descent: 0.19396995293066668\n",
      "Polyak: 0.19396818501395668\n",
      "Nesterov: 0.19396820057694536\n",
      "Adagrad: 56.78663395406466\n",
      "Newton: 0.0792964244521338\n",
      "BFGS: 0.04138513513513514\n",
      "For 5 steps:\n",
      "gradient_descent: 0.18830131847196405\n",
      "Polyak: 0.18829459855111275\n",
      "Nesterov: 0.18829465421661182\n",
      "Adagrad: 2.509177376529712\n",
      "Newton: 0.02148250375448607\n",
      "BFGS: 2.7755575615628914e-17\n",
      "For 10 steps:\n",
      "gradient_descent: 0.17944816291291976\n",
      "Polyak: 0.17943420193013407\n",
      "Nesterov: 0.17943430795736168\n",
      "Adagrad: 0.5794064164874975\n",
      "Newton: 0.0024367092687248015\n",
      "BFGS: 2.7755575615628914e-17\n",
      "For 100 steps:\n",
      "gradient_descent: 0.08651356918466008\n",
      "Polyak: 0.08645791432300226\n",
      "Nesterov: 0.08645817244069645\n",
      "Adagrad: 3.3061609006068693e-12\n",
      "Newton: 0.0\n",
      "BFGS: 2.7755575615628914e-17\n"
     ]
    }
   ],
   "source": [
    "point = np.array([0, 0, 0])\n",
    "_min = np.array([-1. / 6, -11. / 48, 1. / 6])\n",
    "for i in [2, 5, 10, 100]:\n",
    "    print(f'For {i} steps:')\n",
    "    f_analysis(fun_a, aprim, aprimprim, point=point, _min=_min, st=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each method calculated $|f(x_k)-f(x_{min})|$.Learning rates are fixed($\\gamma = 0.001 \\: \\beta = 0.0009$).\n",
    "We can see that for each step size, as expected, BFGS and Newton method are the best one.\n",
    "For the time restriction we can see that Newton method found minimum since its difference is $0.0$. All other functions are inert of time after certain size of steps where we can see that most method stuck close to the actual minima ($\\approx e^{-17}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:01.782100Z",
     "start_time": "2021-09-04T13:26:45.719663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For time of 0.1 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 0.10000228881835938\n",
      "Gradient_descent(7470 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.1000065803527832\n",
      "Polyak(6927 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.10000085830688477\n",
      "Nesterov(4494 steps) 6.688538611854256e-13\n",
      "ELAPSED: 0.1000051498413086\n",
      "Adagrad(4072 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.10000491142272949\n",
      "Newton(7140 steps) 0.0\n",
      "BFGS(3 steps) 2.7755575615628914e-17\n",
      "\n",
      "For time of 1 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 1.0000038146972656\n",
      "Gradient_descent(83661 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000004768371582\n",
      "Polyak(63552 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000114440917969\n",
      "Nesterov(69642 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000081062316895\n",
      "Adagrad(65202 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000009536743164\n",
      "Newton(97373 steps) 0.0\n",
      "BFGS(3 steps) 2.7755575615628914e-17\n",
      "\n",
      "For time of 2 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 2.000006675720215\n",
      "Gradient_descent(190747 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.0000081062316895\n",
      "Polyak(154224 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.000005006790161\n",
      "Nesterov(126741 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.0000083446502686\n",
      "Adagrad(144830 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.0000088214874268\n",
      "Newton(192312 steps) 0.0\n",
      "BFGS(3 steps) 2.7755575615628914e-17\n"
     ]
    }
   ],
   "source": [
    "point = np.array([0, 0, 0])\n",
    "_min = np.array([-1. / 6, -11. / 48, 1. / 6])\n",
    "for i in [0.1, 1, 2]:\n",
    "    print(f'\\nFor time of {i} sec.\\n-----------------------\\n')\n",
    "    f_analysis_time(fun_a, aprim, aprimprim, point=point, _min=_min, _time=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For point (1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:01.807598Z",
     "start_time": "2021-09-04T13:27:01.783834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 steps:\n",
      "gradient_descent: 10.440628606498667\n",
      "Polyak: 10.440293796571396\n",
      "Nesterov: 10.440304768828074\n",
      "Adagrad: 34.96605709118834\n",
      "Newton: 3.6571510957324107\n",
      "BFGS: 3.702304683108269\n",
      "For 5 steps:\n",
      "gradient_descent: 9.475841528115307\n",
      "Polyak: 9.474739332432728\n",
      "Nesterov: 9.474773525354232\n",
      "Adagrad: 0.3825777379005431\n",
      "Newton: 0.9907730731568978\n",
      "BFGS: 0.0\n",
      "For 10 steps:\n",
      "gradient_descent: 8.215791652525828\n",
      "Polyak: 8.213955273136627\n",
      "Nesterov: 8.214006411821455\n",
      "Adagrad: 0.009975862881552638\n",
      "Newton: 0.11238103147358611\n",
      "BFGS: 0.0\n",
      "For 100 steps:\n",
      "gradient_descent: 2.1343989081870274\n",
      "Polyak: 2.1322006461849097\n",
      "Nesterov: 2.132216926598006\n",
      "Adagrad: 4.052314039881821e-15\n",
      "Newton: 2.7755575615628914e-17\n",
      "BFGS: 0.0\n"
     ]
    }
   ],
   "source": [
    "point = np.array([1, 1, 0])\n",
    "_min = np.array([-1. / 6, -11. / 48, 1. / 6])\n",
    "for i in [2, 5, 10, 100]:\n",
    "    print(f'For {i} steps:')\n",
    "    f_analysis(fun_a, aprim, aprimprim, point=point, _min=_min, st=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:17.854585Z",
     "start_time": "2021-09-04T13:27:01.809084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For time of 0.1 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 0.10000824928283691\n",
      "Gradient_descent(6869 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.10001206398010254\n",
      "Polyak(7044 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.10000729560852051\n",
      "Nesterov(6302 steps) 2.7755575615628914e-16\n",
      "ELAPSED: 0.1000063419342041\n",
      "Adagrad(6268 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 0.1000053882598877\n",
      "Newton(7980 steps) 0.0\n",
      "BFGS(5 steps) 0.0\n",
      "\n",
      "For time of 1 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 1.000004529953003\n",
      "Gradient_descent(95685 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000064373016357\n",
      "Polyak(84658 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000081062316895\n",
      "Nesterov(67343 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000052452087402\n",
      "Adagrad(65743 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 1.0000035762786865\n",
      "Newton(78987 steps) 0.0\n",
      "BFGS(5 steps) 0.0\n",
      "\n",
      "For time of 2 sec.\n",
      "-----------------------\n",
      "\n",
      "ELAPSED: 2.000001907348633\n",
      "Gradient_descent(188007 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.000012159347534\n",
      "Polyak(155755 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.000004529953003\n",
      "Nesterov(130491 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.000009536743164\n",
      "Adagrad(120570 steps) 2.7755575615628914e-17\n",
      "ELAPSED: 2.000006914138794\n",
      "Newton(140833 steps) 0.0\n",
      "BFGS(5 steps) 0.0\n"
     ]
    }
   ],
   "source": [
    "point = np.array([1, 1, 0])\n",
    "_min = np.array([-1. / 6, -11. / 48, 1. / 6])\n",
    "for i in [0.1, 1, 2]:\n",
    "    print(f'\\nFor time of {i} sec.\\n-----------------------\\n')\n",
    "    f_analysis_time(fun_a, aprim, aprimprim, point=point, _min=_min, _time=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun B Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For point (1.2,1.2,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:17.890325Z",
     "start_time": "2021-09-04T13:27:17.856589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent: 0.04237239125217664\n",
      "Polyak: 0.0416267489890991\n",
      "Nesterov: 0.04218923813655814\n",
      "Adagrad: 672.9987016724674\n",
      "Newton: 1.8740502074654306\n",
      "BFGS: 0.40476859167591295\n",
      "gradient_descent: 0.01822295618259744\n",
      "Polyak: 0.018219921673633302\n",
      "Nesterov: 0.018222819892398757\n",
      "Adagrad: 66.38255596103494\n",
      "Newton: 1.7070441676347827\n",
      "BFGS: 0.003938551816699398\n",
      "gradient_descent: 0.01810864030289775\n",
      "Polyak: 0.01810794950318427\n",
      "Nesterov: 0.01810809700402333\n",
      "Adagrad: 6.011044131135644\n",
      "Newton: 1.9019254856621228\n",
      "BFGS: 0.00040192392476022954\n",
      "gradient_descent: 0.0168746921999298\n",
      "Polyak: 0.016872981585736753\n",
      "Nesterov: 0.016873097892178543\n",
      "Adagrad: 1.1433201089081284\n",
      "Newton: 2.2119790547865126\n",
      "BFGS: 8.090977814364543e-23\n"
     ]
    }
   ],
   "source": [
    "point = np.array([1.2, 1.2, 1.2])\n",
    "_min = np.array([1, 1, 1])\n",
    "for i in [2, 5, 10, 100]:\n",
    "    f_analysis(fun_b, bprim, bprimprim, point=point, _min=_min, st=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:33.849529Z",
     "start_time": "2021-09-04T13:27:17.891691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELAPSED: 0.10000824928283691\n",
      "Gradient_descent(6149 steps) 7.822863729097724e-05\n",
      "ELAPSED: 0.10000419616699219\n",
      "Polyak(5513 steps) 0.00014121921174761108\n",
      "ELAPSED: 0.10001301765441895\n",
      "Nesterov(5094 steps) 0.00020877402966268765\n",
      "ELAPSED: 0.10001182556152344\n",
      "Adagrad(5095 steps) 0.029056755136369777\n",
      "ELAPSED: 0.10001420974731445\n",
      "Newton(6018 steps) 0.014910309512506199\n",
      "BFGS(18 steps) 8.090977814364543e-23\n",
      "ELAPSED: 1.0000042915344238\n",
      "Gradient_descent(65064 steps) 2.9874162480719717e-26\n",
      "ELAPSED: 1.0000107288360596\n",
      "Polyak(56116 steps) 1.8107779458998617e-25\n",
      "ELAPSED: 1.0000057220458984\n",
      "Nesterov(55016 steps) 5.188884952853526e-25\n",
      "ELAPSED: 1.000002145767212\n",
      "Adagrad(47974 steps) 4.071816495863049e-27\n",
      "ELAPSED: 1.0000243186950684\n",
      "Newton(58694 steps) 5.337432884725366e-27\n",
      "BFGS(18 steps) 8.090977814364543e-23\n",
      "ELAPSED: 2.00000262260437\n",
      "Gradient_descent(144777 steps) 2.9874162480719717e-26\n",
      "ELAPSED: 2.000007390975952\n",
      "Polyak(112219 steps) 2.9874162480719717e-26\n",
      "ELAPSED: 2.0000107288360596\n",
      "Nesterov(116530 steps) 2.9874162480719717e-26\n",
      "ELAPSED: 2.0000128746032715\n",
      "Adagrad(118906 steps) 4.071816495863049e-27\n",
      "ELAPSED: 2.0000009536743164\n",
      "Newton(137769 steps) 5.254010843998244e-27\n",
      "BFGS(18 steps) 8.090977814364543e-23\n"
     ]
    }
   ],
   "source": [
    "point = np.array([1.2, 1.2, 1.2])\n",
    "_min = np.array([1, 1, 1])\n",
    "for i in [0.1, 1, 2]:\n",
    "    f_analysis_time(fun_b, bprim, bprimprim, point=point, _min=_min, _time=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For point (-1,1.2,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:33.887397Z",
     "start_time": "2021-09-04T13:27:33.850958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent: 5.291303548299122\n",
      "Polyak: 5.281960496478046\n",
      "Nesterov: 5.295783131437328\n",
      "Adagrad: 10.998161267050445\n",
      "Newton: 14.229737679572\n",
      "BFGS: 5.096692626292573\n",
      "gradient_descent: 4.242976298680136\n",
      "Polyak: 4.241701324282035\n",
      "Nesterov: 4.24365322394045\n",
      "Adagrad: 22.29760410658125\n",
      "Newton: 12.652678091122368\n",
      "BFGS: 3.6500356730752976\n",
      "gradient_descent: 4.203008679052148\n",
      "Polyak: 4.202995790057172\n",
      "Nesterov: 4.202988048387073\n",
      "Adagrad: 12.9245308651149\n",
      "Newton: 15.88732206933603\n",
      "BFGS: 3.069312912060792\n",
      "gradient_descent: 4.133886443347678\n",
      "Polyak: 4.133820835559854\n",
      "Nesterov: 4.133798263891991\n",
      "Adagrad: 3.9447875666350094\n",
      "Newton: 54.523773553224586\n",
      "BFGS: 7.07550828793846e-24\n"
     ]
    }
   ],
   "source": [
    "point = np.array([-1, 1.2, 1.2])\n",
    "for i in [2, 5, 10, 100]:\n",
    "    f_analysis(fun_b, bprim, bprimprim, point=point, _min=_min, st=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:49.845558Z",
     "start_time": "2021-09-04T13:27:33.888739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELAPSED: 0.10000371932983398\n",
      "Gradient_descent(5949 steps) 0.004676367609846642\n",
      "ELAPSED: 0.1000068187713623\n",
      "Polyak(6359 steps) 0.003030672662654092\n",
      "ELAPSED: 0.10001277923583984\n",
      "Nesterov(5603 steps) 0.006723907525377008\n",
      "ELAPSED: 0.10000443458557129\n",
      "Adagrad(5430 steps) 0.08566325622189815\n",
      "ELAPSED: 0.10000014305114746\n",
      "Newton(6404 steps) 114854898.89923741\n",
      "BFGS(46 steps) 7.07550828793846e-24\n",
      "ELAPSED: 1.0000104904174805\n",
      "Gradient_descent(68799 steps) 6.355322297444997e-27\n",
      "ELAPSED: 1.0000121593475342\n",
      "Polyak(55181 steps) 1.734950393599414e-23\n",
      "ELAPSED: 1.0000004768371582\n",
      "Nesterov(47348 steps) 2.977113909797905e-20\n",
      "ELAPSED: 1.0000102519989014\n",
      "Adagrad(58041 steps) 7.002040328306497e-27\n",
      "ELAPSED: 1.0000030994415283\n",
      "Newton(61234 steps) 7583850039956.156\n",
      "BFGS(46 steps) 7.07550828793846e-24\n",
      "ELAPSED: 2.0000081062316895\n",
      "Gradient_descent(140171 steps) 6.355322297444997e-27\n",
      "ELAPSED: 2.0000154972076416\n",
      "Polyak(119363 steps) 6.355322297444997e-27\n",
      "ELAPSED: 2.0000057220458984\n",
      "Nesterov(111265 steps) 6.355322297444997e-27\n",
      "ELAPSED: 2.0000007152557373\n",
      "Adagrad(115910 steps) 7.002040328306497e-27\n",
      "ELAPSED: 2.0000040531158447\n",
      "Newton(131600 steps) 342908673033968.25\n",
      "BFGS(46 steps) 7.07550828793846e-24\n"
     ]
    }
   ],
   "source": [
    "point = np.array([-1, 1.2, 1.2])\n",
    "for i in [0.1, 1, 2]:\n",
    "    f_analysis_time(fun_b, bprim, bprimprim, point=point, _min=_min, _time=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:49.855115Z",
     "start_time": "2021-09-04T13:27:49.847074Z"
    }
   },
   "outputs": [],
   "source": [
    "def fun(n):\n",
    "    return np.array([[i, i + np.random.uniform(0, 1, 1)[0]]\n",
    "                     for i in range(1, n + 1)])\n",
    "\n",
    "\n",
    "def linreg(points):\n",
    "    N = points.size\n",
    "\n",
    "    def least_squares(points):\n",
    "        x = points[:, 0]\n",
    "        y = points[:, 1]\n",
    "        k = 0\n",
    "        n = 0\n",
    "\n",
    "        def grad_ls(point):\n",
    "            yp = point[0] * x + point[1]\n",
    "            grad_k = (1. / N) * np.sum(x * (yp - y))\n",
    "            grad_n = (1. / N) * np.sum((yp - y))\n",
    "            return np.array([grad_k, grad_n])\n",
    "\n",
    "        def ls_loss_f(point):\n",
    "            return (1. / 2 * N) * np.sum(((point[0] * x + point[1])-y)**2)\n",
    "\n",
    "        def hessian_ls(point):\n",
    "            return np.array([[(1 / N) * np.sum(x**2), (1 / N) * np.sum(x)],\n",
    "                             [(1 / N) * np.sum(x), 1]])\n",
    "\n",
    "        return ls_loss_f, grad_ls,hessian_ls\n",
    "\n",
    "    return least_squares(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:27:49.869024Z",
     "start_time": "2021-09-04T13:27:49.857233Z"
    }
   },
   "outputs": [],
   "source": [
    "def Linear_Regression_time(N, _time,lr=0.001,beta=0.0001):\n",
    "    ls_f, grad_ls,hessian_ls = linreg(fun(N))\n",
    "    point = np.array([0, 0])\n",
    "    v_gd = [\n",
    "        ls_f(val) for val in gradient_descent(\n",
    "            point,lr, grad_ls, isTimed=True, runFor=_time)\n",
    "    ]\n",
    "    v_polyak = [\n",
    "        ls_f(val) for val in polyak(\n",
    "            point, lr, beta, gradient=grad_ls, isTimed=True, runFor=_time)\n",
    "    ]\n",
    "    print(len(v_polyak))\n",
    "    v_nesterov = [\n",
    "        ls_f(val) for val in nesterov(\n",
    "            point, lr, beta, grad_ls, isTimed=True, runFor=_time)\n",
    "    ]\n",
    "    v_adagrad = [\n",
    "        ls_f(val)\n",
    "        for val in adagrad(point, lr*50, grad_ls, isTimed=True, runFor=_time)\n",
    "    ]\n",
    "    plt.plot(np.linspace(1, len(v_gd), len(v_gd)), v_gd, label=\"GD\")\n",
    "    plt.plot(np.linspace(1, len(v_polyak), len(v_polyak)), v_polyak, label=\"Polyak\")\n",
    "    plt.plot(np.linspace(1, len(v_nesterov), len(v_nesterov)), v_nesterov, label=\"Nesterov\")\n",
    "    plt.plot(np.linspace(1, len(v_adagrad), len(v_adagrad)), v_adagrad, label=\"AdaGrad\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('$Steps$')\n",
    "    plt.ylabel('$log(d)$')\n",
    "    plt.title('Distance from $min(f)$ -  steps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:54:03.011712Z",
     "start_time": "2021-09-04T13:54:02.996444Z"
    }
   },
   "outputs": [],
   "source": [
    "def Linear_Regression_steps(N, steps,lr=0.001,beta=0.0001):\n",
    "    ls_f, grad_ls, hessian_ls = linreg(fun(N))\n",
    "    point = np.array([0.5, 0.5])\n",
    "    v_gd =gradient_descent(point,lr, grad_ls,steps=steps)[-1]\n",
    "    v_polyak = polyak(\n",
    "            point, lr, beta, gradient=grad_ls, steps=steps)[-1]\n",
    "    v_nesterov = nesterov(\n",
    "            point, lr, beta, grad_ls, steps=steps)[-1]\n",
    "    v_adagrad = adagrad(point, lr*50, grad_ls,steps=steps)[-1]\n",
    "    print(f'GD:{ls_f(v_gd)},(k,n)= {v_gd}')\n",
    "    print(f'PD:{ls_f(v_polyak)},(k,n)= {v_polyak}')  \n",
    "    print(f'ND:{ls_f(v_nesterov)},(k,n)= {v_nesterov}')  \n",
    "    print(f'ADA:{ls_f(v_adagrad)},(k,n)= {v_adagrad}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:54:03.501797Z",
     "start_time": "2021-09-04T13:54:03.450788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD:226.25994740342375,(k,n)= [0.99832772 0.51696208]\n",
      "PD:226.25972163231444,(k,n)= [0.99832766 0.5169642 ]\n",
      "ND:226.25972165970074,(k,n)= [0.99832766 0.5169642 ]\n",
      "ADA:300.90859555951266,(k,n)= [0.98453111 0.96531355]\n"
     ]
    }
   ],
   "source": [
    "Linear_Regression_steps(50,200,0.001,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:54:06.864861Z",
     "start_time": "2021-09-04T13:54:06.814677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD:800.3540541783688,(k,n)= [0.9989157  0.50737342]\n",
      "PD:800.354043410503,(k,n)= [0.99891571 0.50737335]\n",
      "ND:800.3540434106346,(k,n)= [0.99891571 0.50737335]\n",
      "ADA:4633332.291529985,(k,n)= [0.62711056 0.62706911]\n"
     ]
    }
   ],
   "source": [
    "Linear_Regression_steps(100,200,0.0001,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:54:13.459073Z",
     "start_time": "2021-09-04T13:54:13.395117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD:inf,(k,n)= [-6.80826644e+238 -1.02073036e+236]\n",
      "PD:inf,(k,n)= [-6.71703592e+238 -1.00705262e+236]\n",
      "ND:inf,(k,n)= [-8.41228790e+238 -1.26121352e+236]\n",
      "ADA:46341398702.20458,(k,n)= [0.6272283  0.62722437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50840/2361832673.py:22: RuntimeWarning: overflow encountered in square\n",
      "  return (1. / 2 * N) * np.sum(((point[0] * x + point[1])-y)**2)\n"
     ]
    }
   ],
   "source": [
    "Linear_Regression_steps(1000,200,0.0001,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T13:54:17.209888Z",
     "start_time": "2021-09-04T13:54:17.014294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD:inf,(k,n)= [-5.10684266e+238 -7.65988105e+234]\n",
      "PD:inf,(k,n)= [-5.10684197e+238 -7.65988001e+234]\n",
      "ND:inf,(k,n)= [-5.10685347e+238 -7.65989726e+234]\n",
      "ADA:828988416199367.6,(k,n)= [0.50134231 0.50134231]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50840/2361832673.py:22: RuntimeWarning: overflow encountered in square\n",
      "  return (1. / 2 * N) * np.sum(((point[0] * x + point[1])-y)**2)\n"
     ]
    }
   ],
   "source": [
    "Linear_Regression_steps(10000,200,1e-6,1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that introducing large $N$ gradient descent tends to diverge ($N \\geq 1000$).Starting point is $x_0 = (0.5,0.5)$ Lowering learning rate($\\gamma $) doesn't change the outcome. Observing lower values of $N$ we can that most of the method evaluates parameters $(k,n) \\approx (1,0.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlds] *",
   "language": "python",
   "name": "conda-env-mlds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "763px",
    "left": "29px",
    "top": "111px",
    "width": "381px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
