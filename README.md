### Explanation

In this repository common optimization method for functions are found. Besides theoretical task, method are implemented as algorithms in Python from scratch. These methods are selected due to their use in common Machine Learning applications in models as their optimizers ( e.g. Gradient Descent in ANN, MCMC in Bayesian inference)

### Sections

- Gradient Descent (Polyak,Nesterov,AdaGrad,Newton, BFGS)
- Interior Point Method (Zero order Method)
- Nelder Mead Method (Zero order Method)
- Markov Chain Monte Carlo ( Metropolis - Hastings, Hamiltonian MC, Rejection Sampling)
